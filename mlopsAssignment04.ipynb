{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# # Standard scientific Python imports\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import sklearn\n",
        "# from skimage.transform import rescale, resize\n",
        "# from skimage import transform\n",
        "\n",
        "# # Import datasets, classifiers and performance metrics\n",
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import pandas as pd\n",
        "# import numpy as np \n",
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import sklearn\n",
        "# from skimage.transform import rescale, resize\n",
        "# from skimage import transform\n",
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "# import pandas as pd\n",
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn import tree\n",
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import sklearn\n",
        "# from skimage.transform import rescale, resize\n",
        "# from skimage import transform\n",
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "# import pandas as pd\n",
        "# from sklearn import datasets, svm, metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn import tree\n",
        "# from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "U1a5Wc6VjK3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.transform import rescale, resize\n",
        "from skimage import transform\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "7w015NWTKs-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USING DIGIT DATASET FOR COMPARISION BETWEEN SVM and DECISION TREE"
      ],
      "metadata": {
        "id": "KZK5TjCyDJz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training SVM"
      ],
      "metadata": {
        "id": "cdpuLvAkDSk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gtElm7UjGh4",
        "outputId": "f9e46bf0-04b6-40dc-bbd3-8b6458fedf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8,0.1,0.1]  training Fraction is 0.8 : Test Fraction is 0.1 : Validation Fraction is 0.1 \n",
            "     Gamma    C  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0   0.0100  0.1           0.107168      0.071823       0.083799\n",
            "1   0.0100  0.4           0.567154      0.143646       0.206704\n",
            "2   0.0100  0.5           1.000000      0.182320       0.234637\n",
            "3   0.0100  1.0           1.000000      0.751381       0.832402\n",
            "4   0.0010  0.1           0.972860      0.977901       0.955307\n",
            "5   0.0010  0.4           0.995825      0.994475       0.977654\n",
            "6   0.0010  0.5           0.997912      0.994475       0.977654\n",
            "7   0.0010  1.0           0.997912      0.994475       0.983240\n",
            "8   0.0001  0.1           0.917189      0.922652       0.865922\n",
            "9   0.0001  0.4           0.965901      0.961326       0.938547\n",
            "10  0.0001  0.5           0.969381      0.983425       0.938547\n",
            "11  0.0001  1.0           0.978427      0.983425       0.960894\n",
            "12  0.0005  0.1           0.963814      0.966851       0.944134\n",
            "13  0.0005  0.4           0.990257      0.994475       0.972067\n",
            "14  0.0005  0.5           0.992345      0.994475       0.977654\n",
            "15  0.0005  1.0           0.997216      0.988950       0.988827\n",
            "********************************************************************************\n",
            "Highest accuracy on val dataset is : 0.994475138121547 and corresponsing hyperparamter are {'gamma': 0.0005, 'C': 1.0}.\n",
            "\n",
            "\n",
            "[0.7,0.1,0.2]  training Fraction is 0.7 : Test Fraction is 0.1 : Validation Fraction is 0.2 \n",
            "     Gamma    C  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0   0.0100  0.1           0.105012      0.097222       0.083333\n",
            "1   0.0100  0.4           0.410501      0.133333       0.094444\n",
            "2   0.0100  0.5           0.953063      0.172222       0.133333\n",
            "3   0.0100  1.0           1.000000      0.722222       0.672222\n",
            "4   0.0010  0.1           0.970565      0.969444       0.955556\n",
            "5   0.0010  0.4           0.996022      0.988889       0.988889\n",
            "6   0.0010  0.5           0.997613      0.991667       0.988889\n",
            "7   0.0010  1.0           0.999204      0.991667       0.988889\n",
            "8   0.0001  0.1           0.902944      0.883333       0.888889\n",
            "9   0.0001  0.4           0.960223      0.944444       0.955556\n",
            "10  0.0001  0.5           0.965792      0.955556       0.955556\n",
            "11  0.0001  1.0           0.976134      0.977778       0.966667\n",
            "12  0.0005  0.1           0.962609      0.961111       0.955556\n",
            "13  0.0005  0.4           0.988067      0.983333       0.977778\n",
            "14  0.0005  0.5           0.990453      0.988889       0.977778\n",
            "15  0.0005  1.0           0.997613      0.991667       0.983333\n",
            "TEST\n",
            "[7 0 5 2 4 7 4 6 6 9 4 1 1 7 2 1 8 4 7 9 2 8 9 0 0 4 9 3 2 3 2 4 6 4 6 5 6\n",
            " 6 8 4 3 8 4 0 1 0 4 5 3 5 6 3 6 8 9 9 3 9 2 5 6 5 2 5 6 7 4 2 4 3 6 8 4 2\n",
            " 6 1 3 1 1 9 4 8 9 5 2 6 7 0 4 7 5 7 9 2 3 0 4 9 2 3 3 5 6 9 9 5 5 9 9 9 4\n",
            " 5 7 9 7 8 0 2 5 0 9 9 7 5 0 1 4 5 6 3 8 5 0 5 9 9 5 1 6 3 5 9 1 3 9 0 7 5\n",
            " 1 9 7 0 7 2 3 4 2 7 1 4 8 7 1 0 5 7 4 4 4 2 5 1 5 6 4 5 5 1 9 5]\n",
            "********************************************************************************\n",
            "Highest accuracy on val dataset is : 0.9916666666666667 and corresponsing hyperparamter are {'gamma': 0.0005, 'C': 1.0}.\n",
            "\n",
            "\n",
            "[0.6,0.2,0.2]  training Fraction is 0.6 : Test Fraction is 0.2 : Validation Fraction is 0.2 \n",
            "     Gamma    C  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0   0.0100  0.1           0.207792      0.161111       0.169916\n",
            "1   0.0100  0.4           0.493506      0.200000       0.208914\n",
            "2   0.0100  0.5           0.959184      0.230556       0.228412\n",
            "3   0.0100  1.0           1.000000      0.741667       0.679666\n",
            "4   0.0010  0.1           0.961039      0.947222       0.955432\n",
            "5   0.0010  0.4           0.994434      0.986111       0.988858\n",
            "6   0.0010  0.5           0.996289      0.988889       0.986072\n",
            "7   0.0010  1.0           0.999072      0.991667       0.994429\n",
            "8   0.0001  0.1           0.849722      0.844444       0.830084\n",
            "9   0.0001  0.4           0.954545      0.944444       0.958217\n",
            "10  0.0001  0.5           0.961967      0.950000       0.966574\n",
            "11  0.0001  1.0           0.975881      0.966667       0.977716\n",
            "12  0.0005  0.1           0.958256      0.941667       0.958217\n",
            "13  0.0005  0.4           0.986085      0.980556       0.977716\n",
            "14  0.0005  0.5           0.988868      0.986111       0.983287\n",
            "15  0.0005  1.0           0.997217      0.986111       0.986072\n",
            "********************************************************************************\n",
            "Highest accuracy on val dataset is : 0.9916666666666667 and corresponsing hyperparamter are {'gamma': 0.0005, 'C': 1.0}.\n",
            "\n",
            "\n",
            "[0.5,0.25,0.25]  training Fraction is 0.5 : Test Fraction is 0.25 : Validation Fraction is 0.25 \n",
            "     Gamma    C  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0   0.0100  0.1           0.106904      0.084444       0.097996\n",
            "1   0.0100  0.4           0.420935      0.162222       0.182628\n",
            "2   0.0100  0.5           0.957684      0.151111       0.180401\n",
            "3   0.0100  1.0           1.000000      0.695556       0.694878\n",
            "4   0.0010  0.1           0.963252      0.937778       0.948775\n",
            "5   0.0010  0.4           0.995546      0.964444       0.979955\n",
            "6   0.0010  0.5           0.996659      0.968889       0.982183\n",
            "7   0.0010  1.0           1.000000      0.984444       0.988864\n",
            "8   0.0001  0.1           0.812918      0.786667       0.797327\n",
            "9   0.0001  0.4           0.957684      0.926667       0.953229\n",
            "10  0.0001  0.5           0.958797      0.928889       0.957684\n",
            "11  0.0001  1.0           0.979955      0.948889       0.975501\n",
            "12  0.0005  0.1           0.957684      0.935556       0.942094\n",
            "13  0.0005  0.4           0.985523      0.957778       0.977728\n",
            "14  0.0005  0.5           0.988864      0.960000       0.977728\n",
            "15  0.0005  1.0           0.996659      0.968889       0.982183\n",
            "********************************************************************************\n",
            "Highest accuracy on val dataset is : 0.9844444444444445 and corresponsing hyperparamter are {'gamma': 0.0005, 'C': 1.0}.\n",
            "\n",
            "\n",
            "[0.4,0.3,0.3]  training Fraction is 0.4 : Test Fraction is 0.3 : Validation Fraction is 0.3 \n",
            "     Gamma    C  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0   0.0100  0.1           0.112813      0.090741       0.087199\n",
            "1   0.0100  0.4           0.256267      0.118519       0.107607\n",
            "2   0.0100  0.5           0.777159      0.133333       0.129870\n",
            "3   0.0100  1.0           1.000000      0.538889       0.543599\n",
            "4   0.0010  0.1           0.963788      0.922222       0.944341\n",
            "5   0.0010  0.4           0.997214      0.962963       0.975881\n",
            "6   0.0010  0.5           1.000000      0.964815       0.975881\n",
            "7   0.0010  1.0           1.000000      0.970370       0.985158\n",
            "8   0.0001  0.1           0.642061      0.609259       0.604824\n",
            "9   0.0001  0.4           0.954039      0.924074       0.938776\n",
            "10  0.0001  0.5           0.959610      0.931481       0.953618\n",
            "11  0.0001  1.0           0.977716      0.948148       0.964750\n",
            "12  0.0005  0.1           0.955432      0.918519       0.946197\n",
            "13  0.0005  0.4           0.986072      0.957407       0.975881\n",
            "14  0.0005  0.5           0.987465      0.961111       0.975881\n",
            "15  0.0005  1.0           0.998607      0.966667       0.979592\n",
            "********************************************************************************\n",
            "Highest accuracy on val dataset is : 0.9703703703703703 and corresponsing hyperparamter are {'gamma': 0.0005, 'C': 1.0}.\n",
            "\n",
            "\n",
            "Creating a dataframe of Highest accuracy from above 5 Results and calculating mean and standard deviation\n",
            "   Accuracy_Score\n",
            "0        0.994475\n",
            "1        0.991667\n",
            "2        0.991667\n",
            "3        0.984444\n",
            "4        0.970370\n",
            "Decision Tree Accuracy Mean on validation Dataset 0.9865246572539391\n",
            "Decision Tree Classifier Standard Deviation on validation Dataset 0.009764462833110495\n",
            "\n",
            "\n",
            "Thank You\n"
          ]
        }
      ],
      "source": [
        "def svm_hyperparameters_tunning(imagedataset) :\n",
        "    \n",
        "    n_samples = len(digits.images)\n",
        "    data = imagedataset.reshape((n_samples, -1))\n",
        "    perf_mean_std = list()\n",
        "    predictedcomparetruth = list()\n",
        "    labels = np.zeros((180,), dtype=int)\n",
        "\n",
        "\n",
        "    split_list =  [[0.8,0.1,0.1],[0.70,0.1,0.2],[0.6,0.2,0.2],[0.50,0.25,0.25],[0.4,0.3,0.3]]\n",
        "\n",
        "    for each_split in split_list:\n",
        "        train_frac = each_split[0]\n",
        "        test_frac = each_split[1]\n",
        "        dev_frac = each_split[2]\n",
        "        print(\"[{0},{1},{2}]  training Fraction is {0} : Test Fraction is {1} : Validation Fraction is {2} \".format(train_frac,test_frac,dev_frac))\n",
        "        dev_test_frac=1-train_frac\n",
        "        \n",
        "        \n",
        "        Gamma_list=[0.01 ,0.001, 0.0001, 0.0005]\n",
        "        c_list=[0.1,0.4,0.5,1.0]\n",
        "        h_param_comb=[{'gamma':g,'C':c} for g in Gamma_list for c in c_list]\n",
        "    #     digits = datasets.load_digits()\n",
        "\n",
        "        X_train, X_dev_test, y_train, y_dev_test = train_test_split(data ,digits.target, test_size=dev_test_frac, shuffle=True,random_state=42)\n",
        "        X_test, X_dev, y_test, y_dev = train_test_split(X_dev_test, y_dev_test, test_size=(dev_frac)/dev_test_frac, shuffle=True,random_state=42)\n",
        "\n",
        "        best_acc=-1\n",
        "        best_model=None\n",
        "        best_h_params=None\n",
        "    #     result_dataframe = pd.DataFrame(columns=['Gamma', 'C', 'train','dev','test'])\n",
        "        gamma_list = list()\n",
        "        c_list = list()\n",
        "        train_list = list()\n",
        "        val_list = list()\n",
        "        test_list = list()\n",
        "        # predictedcomparetruth = list()\n",
        "        for com_hyper in h_param_comb:\n",
        "\n",
        "            # Create a classifier: a support vector classifier\n",
        "            clf = svm.SVC()\t\n",
        "            hyper_params=com_hyper\n",
        "            clf.set_params(**hyper_params)\t\n",
        "            clf.fit(X_train, y_train)\n",
        "            predicted_train = clf.predict(X_train)\n",
        "            predicted_dev = clf.predict(X_dev)\n",
        "            predicted_test = clf.predict(X_test)\n",
        "            cur_acc_train=metrics.accuracy_score(y_pred=predicted_train,y_true=y_train)\n",
        "            cur_acc_dev=metrics.accuracy_score(y_pred=predicted_dev,y_true=y_dev)\n",
        "            cur_acc_test=metrics.accuracy_score(y_pred=predicted_test,y_true=y_test)\n",
        "            gamma_list.append(com_hyper['gamma'])\n",
        "            c_list.append(com_hyper['C'])\n",
        "            train_list.append(cur_acc_train)\n",
        "            val_list.append(cur_acc_dev)\n",
        "            test_list.append(cur_acc_test)\n",
        "\n",
        "            if cur_acc_dev>best_acc:\n",
        "                best_acc=cur_acc_dev\n",
        "                best_model=clf\n",
        "                best_h_params=com_hyper\n",
        "\n",
        "        # data = {'Gamma':gamma_list,'C':c_list,'Training_Accuracy':train_list,'Val_Accuracy':val_list,'Test_Accuracy':test_list}\n",
        "        # df = pd.DataFrame(data)\n",
        "        df = pd.DataFrame(list(zip(gamma_list, c_list,train_list,val_list,test_list)),\n",
        "                  columns =['Gamma', 'C','Training_Accuracy','Val_Accuracy','Test_Accuracy'])\n",
        "        print(df)\n",
        "        predicted = best_model.predict(X_test)\n",
        "        # print(predicted)\n",
        "        # print(predicted.shape)\n",
        "        if predicted.shape == (180,) :\n",
        "          labels = predicted # saving the prediction labels on test dataset from best accuracy model with test dataset having 180 records\n",
        "          print(\"TEST\")\n",
        "          print(labels)          \n",
        "          for i in range(len(y_test)):\n",
        "              if labels[i] != y_test[i]:\n",
        "                predictedcomparetruth.append(y_test[i]) # comparing prediction with truth\n",
        "        perf_mean_std.append(best_acc)\n",
        "        print(\"********************************************************************************\")    \n",
        "        print(\"Highest accuracy on val dataset is : {0} and corresponsing hyperparamter are {1}.\".format(best_acc,com_hyper))\n",
        "        # print(\"SVM Accuracy Mean on validation Dataset\",float(df['Val_Accuracy'].mean()))\n",
        "        # print(\"SVM Standard Deviation on validation Dataset\",float(df['Val_Accuracy'].std()))\n",
        "        print(\"\\n\")\n",
        "    return perf_mean_std,labels.tolist(),predictedcomparetruth\n",
        "\n",
        "\n",
        "digits = datasets.load_digits()\n",
        "list_accuracy,labels_svm,wrong_classification_svm = svm_hyperparameters_tunning(digits.images)\n",
        "svm_Accuracy_df = pd.DataFrame(list_accuracy,columns =['Accuracy_Score'])\n",
        "print(\"Creating a dataframe of Highest accuracy from above 5 Results and calculating mean and standard deviation\")\n",
        "print(svm_Accuracy_df)\n",
        "print(\"Decision Tree Accuracy Mean on validation Dataset\",float(svm_Accuracy_df.mean()))\n",
        "print(\"Decision Tree Classifier Standard Deviation on validation Dataset\",float(svm_Accuracy_df.std()))\n",
        "print(\"\\n\")\n",
        "print(\"Thank You\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Decision Tree"
      ],
      "metadata": {
        "id": "MrAWlgeyDYrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decisionTree_hyperparameters_tunning():\n",
        "\n",
        "    digits = datasets.load_digits()   \n",
        "    n_samples = len(digits.images)\n",
        "    data = digits.images.reshape((n_samples, -1))\n",
        "    print(\"Image size in Digit dataset used\",digits.images[-1].shape)\n",
        "    print('\\n')\n",
        "\n",
        "    perf_mean_std = list()\n",
        "    predictedcomparetruth = list()\n",
        "   \n",
        "\n",
        "\n",
        "    split_list =  [[0.8,0.1,0.1],[0.70,0.1,0.2],[0.6,0.2,0.2],[0.50,0.25,0.25],[0.4,0.3,0.3]]\n",
        "\n",
        "    for each_split in split_list:\n",
        "        train_frac = each_split[0]\n",
        "        test_frac = each_split[1]\n",
        "        dev_frac = each_split[2]\n",
        "        print(\"[{0},{1},{2}]  training Fraction is {0} : Test Fraction is {1} : Validation Fraction is {2} \".format(train_frac,test_frac,dev_frac))\n",
        "          \n",
        "        dev_test_frac=1-train_frac\n",
        "\n",
        "        X_train, X_dev_test, y_train, y_dev_test = train_test_split(data ,digits.target, test_size=dev_test_frac, shuffle=True,random_state=42)\n",
        "        X_test, X_dev, y_test, y_dev = train_test_split(X_dev_test, y_dev_test, test_size=(dev_frac)/dev_test_frac, shuffle=True,random_state=42)\n",
        "\n",
        "        best_acc=-1\n",
        "        best_model=None\n",
        "        best_h_params=None\n",
        "\n",
        "        train_list = list()\n",
        "        val_list = list()\n",
        "        test_list = list()\n",
        "        depth_list = list()\n",
        "        \n",
        "        \n",
        "\n",
        "        max_depth_list = [10,20,30,40]\n",
        "\n",
        "        for each_depth in max_depth_list:\n",
        "            clf = tree.DecisionTreeClassifier(max_depth=each_depth)\n",
        "            clf.fit(X_train, y_train)\n",
        "\n",
        "            predicted_train = clf.predict(X_train)\n",
        "            predicted_dev = clf.predict(X_dev)\n",
        "            predicted_test = clf.predict(X_test)\n",
        "            \n",
        "            \n",
        "            \n",
        "            cur_acc_train=metrics.accuracy_score(y_pred=predicted_train,y_true=y_train)\n",
        "            cur_acc_dev=metrics.accuracy_score(y_pred=predicted_dev,y_true=y_dev)\n",
        "            cur_acc_test=metrics.accuracy_score(y_pred=predicted_test,y_true=y_test)\n",
        "\n",
        "\n",
        "            depth_list.append(each_depth)       \n",
        "            train_list.append(cur_acc_train)\n",
        "            val_list.append(cur_acc_dev)\n",
        "            test_list.append(cur_acc_test)\n",
        "            \n",
        "            if cur_acc_dev>best_acc:\n",
        "                best_acc=cur_acc_dev\n",
        "                best_model=clf\n",
        "                best_h_params=each_depth\n",
        "        df = pd.DataFrame(list(zip(depth_list, train_list,val_list,test_list)),\n",
        "                  columns =['Depth_Size', 'Training_Accuracy','Val_Accuracy','Test_Accuracy'])\n",
        "        print(df)\n",
        "        predicted = best_model.predict(X_test)\n",
        "        # print(predicted)\n",
        "        # print(predicted.shape)\n",
        "        if predicted.shape == (180,):\n",
        "          labels = predicted  # saving the prediction labels on test dataset from best accuracy model with test dataset having 180 records\n",
        "          # print(\"TEST\")\n",
        "          # print(\"labels :\",labels)\n",
        "          for i in range(len(y_test)):\n",
        "            if labels[i] != y_test[i]:\n",
        "                predictedcomparetruth.append(y_test[i]) # comparing prediction with truth\n",
        "        perf_mean_std.append(best_acc)\n",
        "        print(\"Highest accuracy on val dataset is : {0} and corresponsing hyperparamter are {1}.\".format(best_acc,best_h_params))\n",
        "        \n",
        "        print(\"------------------------------------------------------------------------------------------------------------------\")        \n",
        "        print(\"\\n\")\n",
        "    # print(\"perf_mean_std\",perf_mean_std)\n",
        "    \n",
        "    return(perf_mean_std,labels.tolist(),predictedcomparetruth)\n",
        "\n",
        "list_accuracy,list_labels_decisionTree,predictedcomparetruthDecisionTree = decisionTree_hyperparameters_tunning()\n",
        "# creating accuracy dataframe\n",
        "Tree_Accuracy_df = pd.DataFrame(list_accuracy,columns =['Accuracy_Score'])\n",
        "print(\"Creating a dataframe of Highest accuracy from above 5 Results and calculating mean and standard deviation\")\n",
        "print(Tree_Accuracy_df)\n",
        "print(\"Decision Tree Accuracy Mean on validation Dataset\",float(Tree_Accuracy_df.mean()))\n",
        "print(\"Decision Tree Classifier Standard Deviation on validation Dataset\",float(Tree_Accuracy_df.std()))\n",
        "print(\"\\n\")\n",
        "print(\"Thank You\")"
      ],
      "metadata": {
        "id": "cGdBfSDBhiXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6079c41-ba51-4684-aa2d-990a57238d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size in Digit dataset used (8, 8)\n",
            "\n",
            "\n",
            "[0.8,0.1,0.1]  training Fraction is 0.8 : Test Fraction is 0.1 : Validation Fraction is 0.1 \n",
            "   Depth_Size  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0          10           0.967989      0.823204       0.893855\n",
            "1          20           1.000000      0.817680       0.905028\n",
            "2          30           1.000000      0.828729       0.888268\n",
            "3          40           1.000000      0.823204       0.899441\n",
            "Highest accuracy on val dataset is : 0.8287292817679558 and corresponsing hyperparamter are 30.\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[0.7,0.1,0.2]  training Fraction is 0.7 : Test Fraction is 0.1 : Validation Fraction is 0.2 \n",
            "   Depth_Size  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0          10           0.974543      0.847222       0.877778\n",
            "1          20           1.000000      0.838889       0.866667\n",
            "2          30           1.000000      0.833333       0.855556\n",
            "3          40           1.000000      0.833333       0.888889\n",
            "Highest accuracy on val dataset is : 0.8472222222222222 and corresponsing hyperparamter are 10.\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[0.6,0.2,0.2]  training Fraction is 0.6 : Test Fraction is 0.2 : Validation Fraction is 0.2 \n",
            "   Depth_Size  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0          10           0.990724      0.844444       0.844011\n",
            "1          20           1.000000      0.850000       0.835655\n",
            "2          30           1.000000      0.844444       0.844011\n",
            "3          40           1.000000      0.863889       0.841226\n",
            "Highest accuracy on val dataset is : 0.8638888888888889 and corresponsing hyperparamter are 40.\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[0.5,0.25,0.25]  training Fraction is 0.5 : Test Fraction is 0.25 : Validation Fraction is 0.25 \n",
            "   Depth_Size  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0          10           0.996659      0.833333       0.861915\n",
            "1          20           1.000000      0.795556       0.835189\n",
            "2          30           1.000000      0.811111       0.846325\n",
            "3          40           1.000000      0.804444       0.853007\n",
            "Highest accuracy on val dataset is : 0.8333333333333334 and corresponsing hyperparamter are 10.\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[0.4,0.3,0.3]  training Fraction is 0.4 : Test Fraction is 0.3 : Validation Fraction is 0.3 \n",
            "   Depth_Size  Training_Accuracy  Val_Accuracy  Test_Accuracy\n",
            "0          10           0.995822      0.800000       0.851577\n",
            "1          20           1.000000      0.812963       0.846011\n",
            "2          30           1.000000      0.801852       0.849722\n",
            "3          40           1.000000      0.809259       0.838590\n",
            "Highest accuracy on val dataset is : 0.812962962962963 and corresponsing hyperparamter are 20.\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Creating a dataframe of Highest accuracy from above 5 Results and calculating mean and standard deviation\n",
            "   Accuracy_Score\n",
            "0        0.828729\n",
            "1        0.847222\n",
            "2        0.863889\n",
            "3        0.833333\n",
            "4        0.812963\n",
            "Decision Tree Accuracy Mean on validation Dataset 0.8372273378350726\n",
            "Decision Tree Classifier Standard Deviation on validation Dataset 0.019280016431667216\n",
            "\n",
            "\n",
            "Thank You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Identify if there is more to the classifier comparison than just the numbers? -- Can you somehow compare the predicted labels, instead of the metrics."
      ],
      "metadata": {
        "id": "Gx0HQDCJFQMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable saving the prediction labels on test dataset from best accuracy SVM model with test dataset having 180 records\n",
        "len(labels_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5NGphj8CMRD",
        "outputId": "351ead13-d818-41b6-b7ee-e031f3a1f9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable saving the prediction labels on test dataset from best accuracy SVM model with test dataset having 180 records\n",
        "len(list_labels_decisionTree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI3BNS9jCMZ-",
        "outputId": "0c500200-6cac-4f0b-9d8a-2c500c430045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying the predicted lables on test dataset  from both the classifiers"
      ],
      "metadata": {
        "id": "-LvVhv8aH3NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM Labels{0}\\nDecisionTreeLabels{1}\".format(labels_svm,list_labels_decisionTree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBFwnazNCMdF",
        "outputId": "ee7f5fdf-ba3b-452f-dd17-07a48ec36343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Labels[7, 0, 5, 2, 4, 7, 4, 6, 6, 9, 4, 1, 1, 7, 2, 1, 8, 4, 7, 9, 2, 8, 9, 0, 0, 4, 9, 3, 2, 3, 2, 4, 6, 4, 6, 5, 6, 6, 8, 4, 3, 8, 4, 0, 1, 0, 4, 5, 3, 5, 6, 3, 6, 8, 9, 9, 3, 9, 2, 5, 6, 5, 2, 5, 6, 7, 4, 2, 4, 3, 6, 8, 4, 2, 6, 1, 3, 1, 1, 9, 4, 8, 9, 5, 2, 6, 7, 0, 4, 7, 5, 7, 9, 2, 3, 0, 4, 9, 2, 3, 3, 5, 6, 9, 9, 5, 5, 9, 9, 9, 4, 5, 7, 9, 7, 8, 0, 2, 5, 0, 9, 9, 7, 5, 0, 1, 4, 5, 6, 3, 8, 5, 0, 5, 9, 9, 5, 1, 6, 3, 5, 9, 1, 3, 9, 0, 7, 5, 1, 9, 7, 0, 7, 2, 3, 4, 2, 7, 1, 4, 8, 7, 1, 0, 5, 7, 4, 4, 4, 2, 5, 1, 5, 6, 4, 5, 5, 1, 9, 5]\n",
            "DecisionTreeLabels[7, 0, 5, 2, 4, 4, 4, 6, 6, 9, 4, 1, 1, 7, 2, 1, 1, 4, 7, 9, 2, 3, 9, 0, 0, 4, 9, 9, 2, 3, 2, 6, 6, 4, 6, 5, 6, 6, 8, 4, 3, 8, 4, 0, 1, 0, 4, 5, 3, 5, 6, 3, 6, 8, 5, 9, 3, 9, 2, 7, 6, 5, 2, 5, 6, 9, 4, 8, 4, 3, 6, 8, 9, 2, 6, 9, 3, 2, 1, 9, 4, 8, 9, 5, 4, 6, 7, 0, 4, 7, 5, 7, 9, 2, 3, 0, 6, 9, 2, 3, 3, 5, 6, 9, 5, 5, 5, 9, 9, 9, 4, 5, 7, 9, 7, 8, 0, 2, 7, 0, 3, 9, 4, 5, 0, 1, 4, 5, 6, 8, 8, 5, 0, 5, 9, 9, 5, 1, 6, 3, 5, 9, 1, 3, 9, 0, 7, 5, 2, 7, 7, 0, 7, 2, 3, 4, 2, 7, 1, 4, 8, 7, 1, 0, 5, 7, 7, 4, 4, 2, 5, 1, 9, 6, 4, 5, 5, 1, 9, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexnotmatching = list()\n",
        "for i in range(len(labels_svm)):\n",
        "  if labels_svm[i] != list_labels_decisionTree[i]:\n",
        "    indexnotmatching.append(i)\n",
        "print(\"index where Predictions are not maching for classified\\n\",indexnotmatching)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmGqQgpBCMih",
        "outputId": "57ed9d0c-fa59-4cdf-c931-4a17449fa167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index where Predictions are not maching for classified\n",
            " [5, 16, 21, 27, 31, 54, 59, 65, 67, 72, 75, 77, 84, 96, 104, 118, 120, 122, 129, 148, 149, 166, 172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying Labels wrongly classified by SVM from Truth in test dataset"
      ],
      "metadata": {
        "id": "Ysq37yXZRHZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_classification_svm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI9AbvnwRVDR",
        "outputId": "dc3d6c10-a6be-42e1-80d5-04f06fe4ce6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying Labels wrongly classified by Decision Tree Classifier from Truth in Test dataset"
      ],
      "metadata": {
        "id": "bvzMMGz5RBKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictedcomparetruthDecisionTree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeeFcDdh-0-W",
        "outputId": "ba6f1b52-3e06-4a6e-a104-bcb892595f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 8, 3, 3, 4, 5, 9, 5, 7, 2, 4, 1, 2, 6, 4, 9, 5, 9, 7, 3, 1, 4, 5, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    }
  ]
}